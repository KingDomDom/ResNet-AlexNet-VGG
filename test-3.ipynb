{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载所需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(BATCH_SIZE):\n",
    "    transform_cifar10_train = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_cifar10_test = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                                download=True, transform=transform_cifar10_train)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True, num_workers=2)\n",
    "\n",
    "    test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                            download=True, transform=transform_cifar10_test)\n",
    "    \n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_set, train_dataloader, test_set, test_dataloader  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试与训练批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, image, target):\n",
    "    # Perform one training batch iteration.\n",
    "    output = model(image)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(output, target)\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "def test_batch(model, image, target):\n",
    "    # Perform one testing batch iteration.\n",
    "    output = model(image)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(output, target)\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_show(process_data):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(process_data['Epoch'], process_data['Train Loss'], label='Train Loss', marker='o')\n",
    "    plt.plot(process_data['Epoch'], process_data['Test Loss'], label='Test Loss', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Testing Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(process_data['Epoch'], process_data['Train Accuracy'], label='Train Accuracy', marker='o')\n",
    "    plt.plot(process_data['Epoch'], process_data['Test Accuracy'], label='Test Accuracy', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Testing Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('accuracy_plot.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程并评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL, model,device):\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_EPOCHS = 20\n",
    "    SAVE_DIR = './log'\n",
    "\n",
    "    train_set, train_dataloader, test_set, test_dataloader = load_data(BATCH_SIZE)\n",
    "    # train_set, _ = torch.utils.data.random_split(train_set,[1280,len(train_set)-1280])\n",
    "    # test_set, _ = torch.utils.data.random_split(train_set,[100,len(train_set)-100])\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step, gamma=gamma)\n",
    "\n",
    "    training_loss,training_acc = [],[]\n",
    "    testing_loss,testing_acc = [],[]\n",
    "\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        torch.cuda.empty_cache()\n",
    "        running_cls_loss = 0.0\n",
    "        running_cls_corrects = 0\n",
    "\n",
    "        for batch_idx, (image, target) in enumerate(train_dataloader):\n",
    "            image = image.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs, loss = train_batch(model, image, target)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_data = loss.data.item()\n",
    "            if np.isnan(loss_data):\n",
    "                raise ValueError('loss is nan while training')\n",
    "            running_cls_loss += loss.item()\n",
    "            running_cls_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss = running_cls_loss / len(train_set)\n",
    "        epoch_acc = running_cls_corrects.double() / len(train_set)\n",
    "        print(f'Epoch: {epoch + 1}/{NUM_EPOCHS} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        training_loss.append(epoch_loss)\n",
    "        training_acc.append(epoch_acc.cpu().detach().numpy())\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % EVAL_INTERVAL == 0 or (epoch + 1) == NUM_EPOCHS:\n",
    "            print('Begin test...')\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_corrects = 0\n",
    "\n",
    "            for batch_idx, (image, target) in enumerate(test_dataloader):\n",
    "                image = image.to(device)\n",
    "                target = target.to(device)\n",
    "\n",
    "                outputs, loss = test_batch(model, image, target)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "            val_loss = val_loss / len(test_set)\n",
    "            val_acc = val_corrects.double() / len(test_set)\n",
    "            print(f'Test Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "            testing_loss.append(val_loss)\n",
    "            testing_acc.append(val_acc.cpu().detach().numpy())\n",
    "\n",
    "            if (epoch + 1) == NUM_EPOCHS:\n",
    "\n",
    "                state = {\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'acc': epoch_acc,\n",
    "                    'epoch': (epoch + 1),\n",
    "                }\n",
    "\n",
    "                if not os.path.exists(SAVE_DIR):\n",
    "                    os.makedirs(SAVE_DIR)\n",
    "\n",
    "                torch.save(state, osp.join(SAVE_DIR, 'checkpoint_%s.pth' % (str(epoch + 1))))       \n",
    "    process_data = {\n",
    "        'Epoch': list(range(1, NUM_EPOCHS + 1)),\n",
    "        'Train Loss': training_loss,\n",
    "        'Train Accuracy': training_acc,\n",
    "        'Test Loss': testing_loss,\n",
    "        'Test Accuracy': testing_acc,\n",
    "    }\n",
    "    plt_show(process_data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数和随机种子定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum = 0.5\n",
    "step = 5\n",
    "gamma = 0.9\n",
    "EVAL_INTERVAL = 2\n",
    "results = []\n",
    "\n",
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用ResNet18训练模型并输出结果:\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1/20 Train Loss: 0.0244 Acc: 0.4319\n",
      "Epoch: 2/20 Train Loss: 0.0149 Acc: 0.6592\n",
      "Begin test...\n",
      "Test Loss: 0.0172 Acc: 0.6366\n",
      "Epoch: 3/20 Train Loss: 0.0109 Acc: 0.7569\n",
      "Epoch: 4/20 Train Loss: 0.0087 Acc: 0.8064\n",
      "Begin test...\n",
      "Test Loss: 0.0131 Acc: 0.7237\n",
      "Epoch: 5/20 Train Loss: 0.0072 Acc: 0.8399\n",
      "Epoch: 6/20 Train Loss: 0.0058 Acc: 0.8692\n",
      "Begin test...\n",
      "Test Loss: 0.0096 Acc: 0.8108\n",
      "Epoch: 7/20 Train Loss: 0.0049 Acc: 0.8905\n",
      "Epoch: 8/20 Train Loss: 0.0042 Acc: 0.9075\n",
      "Begin test...\n",
      "Test Loss: 0.0074 Acc: 0.8458\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m使用ResNet18训练模型并输出结果:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEVAL_INTERVAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(learning_rate, momentum, gamma, step, EVAL_INTERVAL, model, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m running_cls_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (image, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m---> 24\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     27\u001b[0m     outputs, loss \u001b[38;5;241m=\u001b[39m train_batch(model, image, target)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASS = 10\n",
    "model = models.resnet18(weights=None)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, NUM_CLASS)\n",
    "model.to(device)\n",
    "print(\"使用ResNet18训练模型并输出结果:\")\n",
    "result = train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用AlexNet训练模型并输出结果:\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1/20 Train Loss: 0.0320 Acc: 0.2392\n",
      "Epoch: 2/20 Train Loss: 0.0233 Acc: 0.4575\n",
      "Begin test...\n",
      "Test Loss: 0.0197 Acc: 0.5427\n",
      "Epoch: 3/20 Train Loss: 0.0186 Acc: 0.5820\n",
      "Epoch: 4/20 Train Loss: 0.0162 Acc: 0.6406\n",
      "Begin test...\n",
      "Test Loss: 0.0218 Acc: 0.5097\n",
      "Epoch: 5/20 Train Loss: 0.0146 Acc: 0.6753\n",
      "Epoch: 6/20 Train Loss: 0.0130 Acc: 0.7149\n",
      "Begin test...\n",
      "Test Loss: 0.0127 Acc: 0.7265\n",
      "Epoch: 7/20 Train Loss: 0.0120 Acc: 0.7371\n",
      "Epoch: 8/20 Train Loss: 0.0116 Acc: 0.7485\n",
      "Begin test...\n",
      "Test Loss: 0.0196 Acc: 0.5673\n",
      "Epoch: 9/20 Train Loss: 0.0113 Acc: 0.7531\n",
      "Epoch: 10/20 Train Loss: 0.0107 Acc: 0.7680\n",
      "Begin test...\n",
      "Test Loss: 0.0128 Acc: 0.7322\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m使用AlexNet训练模型并输出结果:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEVAL_INTERVAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(learning_rate, momentum, gamma, step, EVAL_INTERVAL, model, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m running_cls_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (image, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m---> 24\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     27\u001b[0m     outputs, loss \u001b[38;5;241m=\u001b[39m train_batch(model, image, target)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASS = 10\n",
    "model = models.alexnet(weights=None)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, NUM_CLASS)\n",
    "model.to(device)\n",
    "print(\"使用AlexNet训练模型并输出结果:\")\n",
    "result = train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用VGG11训练模型并输出结果:\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1/20 Train Loss: 0.0322 Acc: 0.2355\n",
      "Epoch: 2/20 Train Loss: 0.0217 Acc: 0.4977\n",
      "Begin test...\n",
      "Test Loss: 0.0200 Acc: 0.5618\n",
      "Epoch: 3/20 Train Loss: 0.0155 Acc: 0.6509\n",
      "Epoch: 4/20 Train Loss: 0.0123 Acc: 0.7280\n",
      "Begin test...\n",
      "Test Loss: 0.0158 Acc: 0.6623\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m使用VGG11训练模型并输出结果:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEVAL_INTERVAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(learning_rate, momentum, gamma, step, EVAL_INTERVAL, model, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m running_cls_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (image, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m---> 24\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     27\u001b[0m     outputs, loss \u001b[38;5;241m=\u001b[39m train_batch(model, image, target)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASS = 10\n",
    "model = models.vgg11(weights=None)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, NUM_CLASS)\n",
    "model.to(device)\n",
    "print(\"使用VGG11训练模型并输出结果:\")\n",
    "result = train_and_evaluate(learning_rate, momentum, gamma, step, EVAL_INTERVAL,model,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
